{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Core libraries\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# RDKit for chemical informatics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine, pdist\n",
    "from scipy.stats import ttest_ind\n",
    "from joblib import Parallel, delayed\n",
    "# Visualization tools\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Machine learning and clustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "from normalisation import JumpExplorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_average_precision_for_hit(hit_embedding, all_embeddings, all_labels):\n",
    "    # Compute cosine similarity of the hit with all samples\n",
    "    similarities = cosine_similarity(hit_embedding.reshape(1, -1), all_embeddings).flatten()\n",
    "\n",
    "    # Rank indices based on similarity\n",
    "    ranked_indices = np.argsort(-similarities)  # Descending order\n",
    "    ranked_labels = all_labels[ranked_indices]  # Get labels of ranked samples\n",
    "\n",
    "    # Compute precision at each rank\n",
    "    precisions = []\n",
    "    num_hits = 0\n",
    "    for rank, rel_label in enumerate(ranked_labels, start=1):\n",
    "        if rel_label == 1:\n",
    "            num_hits += 1\n",
    "            precisions.append(num_hits / rank)\n",
    "\n",
    "    # Compute average precision for this 'hit' sample\n",
    "    return np.mean(precisions) if precisions else 0\n",
    "\n",
    "\n",
    "\n",
    "def compute_phenotypic_similarity(df):\n",
    "    embeddings = np.stack(df['Embeddings_mean'])  \n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    return similarity_matrix\n",
    "\n",
    "def visualize_similarity_matrix(df, similarity_matrix, fontsize_sim=14):\n",
    "    \"\"\"\n",
    "    Visualise la matrice de similarité cosinus avec les valeurs affichées.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame contenant la colonne Metadata_JCP2022.\n",
    "        similarity_matrix: numpy array, matrice de similarité cosinus.\n",
    "    \"\"\"\n",
    "    ids = df['Metadata_JCP2022'].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Matrice de similarité\n",
    "    cax = ax.imshow(similarity_matrix, cmap='viridis', interpolation='none')  # Suppression de l'interpolation\n",
    "    ax.set_title('Cosine Similarity Matrix', fontsize=14)\n",
    "    ax.set_xticks(range(len(ids)))\n",
    "    ax.set_yticks(range(len(ids)))\n",
    "    ax.set_xticklabels(ids, rotation=90, fontsize=8)\n",
    "    ax.set_yticklabels(ids, fontsize=8)\n",
    "\n",
    "    # Supprimer les lignes blanches entre les pixels\n",
    "    ax.set_xticks([], minor=True)\n",
    "    ax.set_yticks([], minor=True)\n",
    "    ax.grid(False)  # Désactiver les grilles\n",
    "\n",
    "    # Ajouter les valeurs dans les cases\n",
    "    for i in range(similarity_matrix.shape[0]):\n",
    "        for j in range(similarity_matrix.shape[1]):\n",
    "            value = f\"{similarity_matrix[i, j]:.2f}\"  # Formater à 2 décimales\n",
    "            ax.text(j, i, value, ha='center', va='center', fontsize=fontsize_sim, color='white')\n",
    "\n",
    "    # Ajouter une barre de couleur\n",
    "    plt.colorbar(cax, ax=ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def hierarchical_clustering_and_visualization(df, similarity_matrix, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Effectue un clustering hiérarchique sur les molécules et visualise les résultats.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame contenant les molécules et leurs métadonnées.\n",
    "        similarity_matrix (np.ndarray): Matrice de similarité entre les molécules.\n",
    "        threshold (float): Seuil pour déterminer les clusters à partir du dendrogramme.\n",
    "    \"\"\"\n",
    "    # Convertir la matrice de similarité en matrice de dissimilarité\n",
    "    dissimilarity = 1 - similarity_matrix\n",
    "\n",
    "    # Créer un linkage pour le clustering hiérarchique\n",
    "    linkage_matrix = linkage(dissimilarity, method='average')\n",
    "\n",
    "    # Afficher le dendrogramme\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    dendrogram(linkage_matrix, labels=df['Metadata_JCP2022'].values, leaf_rotation=90)\n",
    "    plt.title(\"Dendrogramme de clustering hiérarchique\")\n",
    "    plt.xlabel(\"Molécules\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--', label=f'Seuil {threshold}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Déterminer les clusters à partir du seuil\n",
    "    clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')\n",
    "    df['Cluster'] = clusters\n",
    "    df_sorted = df.sort_values(by='Cluster').reset_index(drop=True)\n",
    "\n",
    "    # Visualisation des molécules par cluster\n",
    "    for cluster_id in sorted(df['Cluster'].unique()):\n",
    "        cluster_df = df[df['Cluster'] == cluster_id]\n",
    "        mols = [Chem.MolFromInchi(inchi) for inchi in cluster_df['Metadata_InChI']]\n",
    "        legends = list(cluster_df['Metadata_JCP2022'].astype(str))\n",
    "\n",
    "        print(f\"Cluster {cluster_id} - {len(cluster_df)} molécules\")\n",
    "        img = Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200), legends=legends)\n",
    "        display(img)\n",
    "    return df_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cross data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_db_path = \"/home/maxime/data/cell_painting/paper_data/BindingDB_All.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_db_path = \"/projects/synsight/repos/phenospace/normalisation/publication/pathways/data/BindingDB_All_202412_tsv(1).zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bd = pd.read_csv(binding_db_path, sep='\\t', on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JUMP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenom = pd.read_parquet('/projects/synsight/data/openphenom/norm_2_compounds_embeddings.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bd.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'Ligand InChI',\n",
    "    'UniProt (SwissProt) Entry Name of Target Chain',\n",
    "    'UniProt (SwissProt) Recommended Name of Target Chain',\n",
    "    'Target Source Organism According to Curator or DataSource','Kd (nM)', 'EC50 (nM)','Article DOI',\n",
    "    \n",
    "]\n",
    "\n",
    "new_df = df_bd[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = []\n",
    "for i in new_df['UniProt (SwissProt) Entry Name of Target Chain']:\n",
    "    try:\n",
    "        genes.append(i.split('_')[0])\n",
    "    except:\n",
    "        genes.append(None)\n",
    "print(set(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['gene_symbol'] = genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = new_df[(new_df['Target Source Organism According to Curator or DataSource']=='Homo sapiens')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['gene_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = filtered_df.merge(df_phenom, left_on='Ligand InChI', right_on='Metadata_InChI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Ligand InChI'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_final['gene_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['gene_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Metadata_JCP2022'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final['Metadata_JCP2022']=='JCP2022_097466']['gene_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_dfs = {}  # Ensure it is a dictionary\n",
    "\n",
    "for gene in df_final['gene_symbol'].unique():\n",
    "    gene_df = df_final[df_final['gene_symbol'] == gene][['Metadata_JCP2022', 'Metadata_InChI', 'Embeddings_mean']]\n",
    "    genes_dfs[gene] = gene_df.drop_duplicates(subset='Metadata_JCP2022').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Comptage du nombre de JCP_ID par molécule\n",
    "molecule_counts = df_final.groupby('gene_symbol')['Metadata_JCP2022'].nunique().reset_index()\n",
    "molecule_counts.columns = ['gene_symbol', 'Number of JCP_ID']\n",
    "\n",
    "# Tri des molécules par nombre de JCP_ID (optionnel)\n",
    "molecule_counts = molecule_counts.sort_values(by='Number of JCP_ID', ascending=False)[:10]\n",
    "\n",
    "# Création du plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='gene_symbol', y='Number of JCP_ID', data=molecule_counts, palette=\"viridis\")\n",
    "\n",
    "# Personnalisation\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.xlabel(\"gene_symbol\")\n",
    "plt.ylabel(\"Nombre de JCP_ID\")\n",
    "plt.title(\"Nombre de JCP_ID par gene_symbol\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Affichage\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse thoses informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = genes_dfs['GSK3B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchi_list = df_final['Metadata_InChI'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenom['Metadata_Bioactivity'] = df_phenom['Metadata_InChI'].apply(lambda x: 'hit' if x in inchi_list else 'nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenom['Metadata_Bioactivity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hits = df_phenom[df_phenom['Metadata_Bioactivity'] == 'hit']\n",
    "non_hits = df_phenom[df_phenom['Metadata_Bioactivity'] != 'hit']\n",
    "\n",
    "hits_embeddings = np.stack(hits['Embeddings_mean'].values).astype(np.float16)\n",
    "all_embeddings = np.stack(df_phenom['Embeddings_mean'].values).astype(np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = (df_phenom['Metadata_Bioactivity'] == 'hit').astype(int).values\n",
    "\n",
    "average_precisions = Parallel(n_jobs=40)(\n",
    "    delayed(compute_average_precision_for_hit)(hit_embedding, all_embeddings, all_labels)\n",
    "    for hit_embedding in tqdm(hits_embeddings)\n",
    ")\n",
    "\n",
    "mAP = np.mean(average_precisions)\n",
    "\n",
    "print(f\"Mean Average Precision (mAP): {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_labels)\n",
    "\n",
    "average_precisions = Parallel(n_jobs=40)(\n",
    "    delayed(compute_average_precision_for_hit)(hit_embedding, all_embeddings, all_labels)\n",
    "    for hit_embedding in tqdm(hits_embeddings)\n",
    ")\n",
    "\n",
    "mAP = np.mean(average_precisions)\n",
    "\n",
    "print(f\"Mean Average Precision (mAP): {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enrichment_factor_at_n(hit_embedding, all_embeddings, all_labels, n_percent=1):\n",
    "    \"\"\"\n",
    "    Calculate the enrichment factor (EF) at n% for a given 'hit' embedding, excluding the control positive.\n",
    "\n",
    "    Parameters:\n",
    "    - hit_embedding: numpy array, the embedding of the 'hit' sample.\n",
    "    - all_embeddings: numpy array, embeddings of all samples.\n",
    "    - all_labels: numpy array, binary labels for all samples (1 for 'hit', 0 otherwise).\n",
    "    - n_percent: float, the percentage (0-100) of the dataset to consider for EF calculation.\n",
    "\n",
    "    Returns:\n",
    "    - float, the Enrichment Factor at n%.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarity of the hit with all samples\n",
    "    similarities = cosine_similarity(hit_embedding.reshape(1, -1), all_embeddings).flatten()\n",
    "\n",
    "    # Rank indices based on similarity\n",
    "    ranked_indices = np.argsort(-similarities)  # Descending order\n",
    "    ranked_labels = all_labels[ranked_indices]  # Get labels of ranked samples\n",
    "\n",
    "    # Remove the first entry (control positive)\n",
    "    ranked_indices = ranked_indices[1:]  # Exclude the first index\n",
    "    ranked_labels = ranked_labels[1:]    # Exclude the first label\n",
    "\n",
    "    # Calculate top n% cutoff\n",
    "    n_top = max(1, int(len(ranked_labels) * (n_percent / 100)))  # At least 1 sample\n",
    "\n",
    "    # Count hits in the top n% of ranked samples\n",
    "    hits_in_top_n = np.sum(ranked_labels[:n_top])\n",
    "\n",
    "    # Total hits in the dataset\n",
    "    total_hits = np.sum(all_labels)\n",
    "\n",
    "    # Compute EF\n",
    "    if total_hits == 0:  # Avoid division by zero\n",
    "        return 0.0\n",
    "    enrichment_factor = (hits_in_top_n / n_top) / (total_hits / len(all_labels))\n",
    "\n",
    "    return enrichment_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = (df_phenom['Metadata_Bioactivity'] == 'hit').astype(int).values\n",
    "\n",
    "enrichment_factor = Parallel(n_jobs=40)(\n",
    "    delayed(compute_enrichment_factor_at_n)(hit_embedding, all_embeddings, all_labels)\n",
    "    for hit_embedding in tqdm(hits_embeddings)\n",
    ")\n",
    "\n",
    "mEF = np.mean(enrichment_factor)\n",
    "maxEF = np.max(enrichment_factor)\n",
    "print(f\"Mean Normalized Enrichment Factor (mEF): {mEF}\")\n",
    "print(f\"Max Normalized Enrichment Factor (mEF): {maxEF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_control_idx = np.argmax(enrichment_factor)\n",
    "\n",
    "# Retrieve the corresponding best hit embedding and its cosine similarities\n",
    "best_hit_embedding = hits_embeddings[best_control_idx]\n",
    "similarities = cosine_similarity(best_hit_embedding.reshape(1, -1), all_embeddings).flatten()\n",
    "\n",
    "# Rank the indices based on similarity (descending order)\n",
    "ranked_indices = np.argsort(-similarities)\n",
    "ranked_similarities = similarities[ranked_indices]\n",
    "ranked_labels = all_labels[ranked_indices]\n",
    "\n",
    "# Prepare data for plotting\n",
    "distances = np.arange(1, len(ranked_similarities) + 1)  # Distance ranking\n",
    "\n",
    "# Updated plot with non-hits as semi-transparent gray and hits as red with larger markers\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot non-hits\n",
    "non_hits_mask = ranked_labels == 0\n",
    "plt.scatter(\n",
    "    distances[non_hits_mask],\n",
    "    ranked_similarities[non_hits_mask],\n",
    "    c='gray',\n",
    "    alpha=0.01,\n",
    "    s=1,  # Smaller marker size\n",
    "    label=\"Non-Hits\"\n",
    ")\n",
    "\n",
    "# Plot hits\n",
    "hits_mask = ranked_labels == 1\n",
    "plt.scatter(\n",
    "    distances[hits_mask],\n",
    "    ranked_similarities[hits_mask],\n",
    "    c='red',\n",
    "    alpha=1.0,\n",
    "    s=2,  # Larger marker size\n",
    "    label=\"Hits\"\n",
    ")\n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"Distance Ranking vs Cosine Similarity\", fontsize=14)\n",
    "plt.xlabel(\"Distance Ranking\", fontsize=12)\n",
    "plt.ylabel(\"Cosine Similarity\", fontsize=12)\n",
    "plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for hits and non-hits\n",
    "hits_similarities = ranked_similarities[ranked_labels == 1]\n",
    "non_hits_similarities = ranked_similarities[ranked_labels == 0]\n",
    "\n",
    "# Plot 1: Kernel Density Estimate (KDE) of Cosine Similarity\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(hits_similarities, color=\"red\", label=\"Hits\", fill=True, alpha=0.5)\n",
    "sns.kdeplot(non_hits_similarities, color=\"gray\", label=\"Non-Hits\", fill=True, alpha=0.5)\n",
    "plt.title(\"KDE of Cosine Similarity for Hits vs Non-Hits\", fontsize=14)\n",
    "plt.xlabel(\"Cosine Similarity\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize lists to accumulate similarities and labels for all hits\n",
    "all_ranked_similarities = []\n",
    "all_ranked_labels = []\n",
    "\n",
    "# Loop through all hits and compute similarities for each as control positive\n",
    "for hit_idx in tqdm(range(len(hits_embeddings))):\n",
    "    # Get the current hit embedding\n",
    "    current_hit_embedding = hits_embeddings[hit_idx]\n",
    "    \n",
    "    # Compute cosine similarities with all embeddings\n",
    "    similarities = cosine_similarity(current_hit_embedding.reshape(1, -1), all_embeddings).flatten()\n",
    "    \n",
    "    # Exclude the control positive (first element) from the ranked indices and labels\n",
    "    similarities = np.delete(similarities, hit_idx)  # Exclude the current hit\n",
    "    labels = np.delete(all_labels, hit_idx)  # Exclude the label of the current hit\n",
    "    \n",
    "    # Rank the indices based on similarity (descending order)\n",
    "    ranked_indices = np.argsort(-similarities)\n",
    "    ranked_similarities = similarities[ranked_indices]\n",
    "    ranked_labels = labels[ranked_indices]\n",
    "    \n",
    "    # Append ranked similarities and labels\n",
    "    all_ranked_similarities.extend(ranked_similarities)\n",
    "    all_ranked_labels.extend(ranked_labels)\n",
    "\n",
    "# Convert to numpy arrays for easier processing\n",
    "all_ranked_similarities = np.array(all_ranked_similarities)\n",
    "all_ranked_labels = np.array(all_ranked_labels)\n",
    "\n",
    "# Separate similarities for hits and non-hits\n",
    "hits_similarities = all_ranked_similarities[all_ranked_labels == 1]\n",
    "non_hits_similarities = all_ranked_similarities[all_ranked_labels == 0]\n",
    "\n",
    "# Plot KDE for all hits as control positives excluding the control positive\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(hits_similarities, color=\"red\", label=\"Hits\", fill=True, alpha=0.5)\n",
    "sns.kdeplot(non_hits_similarities, color=\"gray\", label=\"Non-Hits\", fill=True, alpha=0.5)\n",
    "plt.title(\"KDE of Cosine Similarity for All Hits Excluding Control Positives\", fontsize=14)\n",
    "plt.xlabel(\"Cosine Similarity\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenom['Metadata_Bioactivity'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenom.to_parquet('/projects/synsight/data/openphenom/norm_2_compounds_embeddings_g2m.parquet', index=False)\n",
    "\n",
    "\n",
    "df_phenom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hits = df_phenom[df_phenom['Metadata_Bioactivity'] == 'hit']\n",
    "\n",
    "# Filtrer un échantillon aléatoire de ~500 non-hits\n",
    "df_non_hits = df_phenom[df_phenom['Metadata_Bioactivity'] == 'nan'].sample(n=10*len(df_hits), random_state=42)\n",
    "\n",
    "# Combiner les hits et les non-hits\n",
    "df_phenom_test = pd.concat([df_hits, df_non_hits], ignore_index=True)\n",
    "\n",
    "# Mélanger les lignes pour éviter tout biais d'ordre\n",
    "df_phenom_test = df_phenom_test.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def pairwise_similarities(group, metric=\"cosine\", n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Calcul optimisé des distances intra-groupe.\n",
    "    \"\"\"\n",
    "    group_array = np.array(group, dtype=np.float32)  # Convertir en float32\n",
    "    similarity_matrix = cosine_similarity(group_array, group_array, dense_output=True)\n",
    "    return similarity_matrix[np.triu_indices(len(group_array), k=1)]\n",
    "\n",
    "\n",
    "def compute_inter_group_similarities(group_a, group_b, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Calcul optimisé des distances inter-groupe.\n",
    "    \"\"\"\n",
    "    group_a_array = np.array(group_a, dtype=np.float32)  # Convertir en float32\n",
    "    group_b_array = np.array(group_b, dtype=np.float32)  # Convertir en float32\n",
    "    similarity_matrix = cosine_similarity(\n",
    "        group_a_array,\n",
    "        group_b_array,\n",
    "        dense_output=True,\n",
    "    )\n",
    "    return similarity_matrix.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_phenom_test\n",
    "\n",
    "\n",
    "group_a = df[df['Metadata_Bioactivity'] == 'hit']['Embeddings_mean'].apply(\n",
    "    lambda x: np.array(x, dtype=np.float32)\n",
    ").tolist()\n",
    "\n",
    "group_b = df[df['Metadata_Bioactivity'] == 'nan']['Embeddings_mean'].apply(\n",
    "    lambda x: np.array(x, dtype=np.float32)\n",
    ").tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcul des distances intra-groupe\n",
    "print(\"Calcul des distances intra-groupe...\")\n",
    "\n",
    "distances_a = pairwise_similarities(group_a, metric='cosine', n_jobs=-1)\n",
    "print(\"Moyenne intra-groupe A :\", np.mean(distances_a))\n",
    "distances_b = pairwise_similarities(group_b, metric='cosine', n_jobs=-1)\n",
    "print(\"Moyenne intra-groupe B :\", np.mean(distances_b))\n",
    "\n",
    "print(\"Calcul des distances inter-groupe...\")\n",
    "all_distances = compute_inter_group_similarities(group_a, group_b, n_jobs=-1)\n",
    "\n",
    "print(\"Moyenne inter-groupe A-B :\", np.mean(all_distances))\n",
    "\n",
    "print(\"Calcul du test statistique...\")\n",
    "t_stat, p_value = ttest_ind(distances_a, distances_b, equal_var=False)\n",
    "# Afficher la p-value avec plus de précision\n",
    "print(f\"T-statistique : {t_stat:.6f}\")\n",
    "print(f\"P-value (format standard) : {p_value:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=10, suppress=False)  # Suppress False pour afficher en notation scientifique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Les données pour le boxplot\n",
    "data = [distances_a, distances_b, all_distances]\n",
    "labels = ['Intra-groupe A (hits)', 'Intra-groupe B (non-hits)', 'Inter-groupe A-B']\n",
    "\n",
    "# Création du boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(data, labels=labels, showmeans=True, meanline=True)\n",
    "\n",
    "# Personnalisation de l'affichage\n",
    "plt.title('Distribution des distances')\n",
    "plt.ylabel('Cosine Distance')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Les données pour le violin plot\n",
    "data = [distances_a, distances_b, all_distances]\n",
    "labels = ['Intra-groupe A (hits)', 'Intra-groupe B (non-hits)', 'Inter-groupe A-B']\n",
    "\n",
    "# Création du graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Couleurs personnalisées\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Couleurs pour chaque groupe\n",
    "\n",
    "# Création des violons avec des couleurs personnalisées\n",
    "parts = plt.violinplot(data, showmeans=True, showextrema=True, showmedians=True)\n",
    "\n",
    "# Ajouter les couleurs aux violons\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(colors[i])  # Couleur de remplissage\n",
    "    pc.set_edgecolor('black')   # Contour noir\n",
    "    pc.set_alpha(0.8)           # Transparence\n",
    "\n",
    "# Personnalisation des indicateurs (moyenne, médiane, etc.)\n",
    "parts['cmeans'].set_color('red')     # Moyenne en rouge\n",
    "parts['cmedians'].set_color('blue')  # Médiane en bleu\n",
    "parts['cmins'].set_color('black')    # Minimum en noir\n",
    "parts['cmaxes'].set_color('black')   # Maximum en noir\n",
    "\n",
    "# Ajout des labels pour chaque violon\n",
    "plt.xticks(ticks=range(1, len(labels) + 1), labels=labels)\n",
    "\n",
    "# Personnalisation du graphique\n",
    "plt.title('Distribution des distances (avec couleurs)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Cosine Distance', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Préparer les données et les étiquettes\n",
    "all_embeddings = np.array(df['Embeddings_mean'].tolist(), dtype=np.float16)\n",
    "labels = df['Metadata_Bioactivity'].apply(lambda x: 'hit' if x == 'hit' else 'non-hit')\n",
    "\n",
    "# Réduction de dimension avec UMAP\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42, metric='cosine')\n",
    "embeddings_2d = umap_reducer.fit_transform(all_embeddings)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label in labels.unique():\n",
    "    mask = labels == label\n",
    "    plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], label=label, alpha=0.6, s=10)\n",
    "plt.title(\"Visualisation UMAP des embeddings\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Préparer les données pour la classification\n",
    "X = all_embeddings  # Les embeddings\n",
    "y = (df['Metadata_Bioactivity'] == 'hit').astype(int)  # 1 pour hit, 0 pour non-hit\n",
    "\n",
    "# Diviser en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Entraîner une régression logistique\n",
    "logreg = LogisticRegression(max_iter=500, solver='saga', penalty='l2', C=0.1, n_jobs=-1)  # L1 pour sélectionner les dimensions importantes\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Importance des dimensions\n",
    "feature_importance = np.abs(logreg.coef_[0])\n",
    "important_dimensions = np.argsort(feature_importance)[::-1][:10]  # Top 10 dimensions\n",
    "\n",
    "print(\"Top 10 dimensions les plus importantes :\", important_dimensions)\n",
    "print(\"Scores associés :\", feature_importance[important_dimensions])\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = logreg.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC-ROC :\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JUMP Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "jcps = df_final['Metadata_JCP2022'].to_list()\n",
    "jump_explo = JumpExplorer()\n",
    "jump_explo.figsize = (10, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_explo.plot_multiple_images(num_cols=3, num_rows=3,plot_title=False, Metadata_JCP2022=\"JCP2022_005529\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_explo.plot_images(max_images=3, title_metadata=[], plot_channels=False, plot_perturbations=True, Metadata_JCP2022=\"JCP2022_005529\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_explo.plot_images(max_images=3, title_metadata=[], plot_channels=False, plot_perturbations=True, Metadata_JCP2022=\"JCP2022_078377\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_explo.plot_multiple_images(num_cols=3, num_rows=3,plot_title=True, Metadata_JCP2022=\"JCP2022_001983\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['gene_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
