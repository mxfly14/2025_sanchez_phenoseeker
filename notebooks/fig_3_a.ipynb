{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phenoseeker import BioproxyEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
    "import matplotlib.pyplot as plt\n",
    "from pingouin import compute_effsize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"dinov2_g\"\n",
    "base_path = Path(\"/projects/synsight/data/jump_embeddings/compounds_embeddings/\")\n",
    "npy_file = base_path / model / \"Embeddings_norm.npy\"\n",
    "parquet_metadata = base_path / model / Path(\"metadata.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # To get those datas, see README.md \n",
    "\n",
    "screens_folders = {\n",
    " #   \"Curie\": Internal data, we can't share them\n",
    "    \"ChEMBL\": Path(\"/projects/synsight/repos/phenoseeker/data/ChEMBL/assays_csv\"),\n",
    "    \"Lit-PCBA\": Path(\"/projects/synsight/repos/phenoseeker/data/Lit_PCBA/csv_files\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = BioproxyEvaluator(\n",
    "    parquet_metadata,\n",
    "    npy_file,\n",
    "    screens_folders,\n",
    "    embeddings_name=\"Embeddings_dinov2\",\n",
    "    embeddings_entity=\"compound\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in eval.screen_embedding_managers.keys():\n",
    "    print(source)\n",
    "    for screen in tqdm(eval.screen_embedding_managers[source].keys()):\n",
    "        eval.screen_embedding_managers[source][screen].compute_distance_matrix(\n",
    "            \"Embeddings_dinov2\", \"cosine\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_stars(p_value):\n",
    "    \"\"\"\n",
    "    Assign significance stars based on the p-value.\n",
    "    \"\"\"\n",
    "    if p_value < 0.00001:\n",
    "        return \"*****\"\n",
    "    elif p_value < 0.0001:\n",
    "        return \"****\"\n",
    "    elif p_value < 0.001:\n",
    "        return \"***\"\n",
    "    elif p_value < 0.01:\n",
    "        return \"**\"\n",
    "    elif p_value < 0.05:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"ns\"\n",
    "\n",
    "\n",
    "def run_normality_test(diff_array):\n",
    "    \"\"\"\n",
    "    Run Shapiro-Wilk normality test on the differences between paired samples.\n",
    "\n",
    "    Parameters:\n",
    "        diff_array (np.array): Difference between two paired samples.\n",
    "\n",
    "    Returns:\n",
    "        stat (float): Shapiro-Wilk test statistic.\n",
    "        p_value (float): p-value from the test.\n",
    "    \"\"\"\n",
    "    stat, p_value = shapiro(diff_array)\n",
    "    return stat, p_value\n",
    "\n",
    "\n",
    "def choose_and_run_test(\n",
    "    data1, data2, alternative=\"two-sided\", alpha=0.05, zero_method=\"wilcox\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Check normality of differences and run the appropriate paired test.\n",
    "\n",
    "    If the differences are normally distributed (p > alpha from the Shapiro-Wilk test),\n",
    "    a paired t-test is applied. Otherwise, the Wilcoxon signed-rank test is used.\n",
    "\n",
    "    Parameters:\n",
    "        data1, data2 (np.array): Paired data arrays.\n",
    "        alternative (str): Alternative hypothesis ('greater' by default).\n",
    "        alpha (float): Significance level.\n",
    "        zero_method (str): Zero method for the Wilcoxon test.\n",
    "\n",
    "    Returns:\n",
    "        test_name (str): Name of the test used.\n",
    "        test_statistic (float): Test statistic value.\n",
    "        p_value (float): p-value from the test.\n",
    "        norm_p_value (float): p-value from the Shapiro-Wilk normality test.\n",
    "    \"\"\"\n",
    "    differences = data1 - data2\n",
    "    stat_norm, p_norm = run_normality_test(differences)\n",
    "\n",
    "    if p_norm > alpha:\n",
    "        # Normality holds, so we use paired t-test.\n",
    "        test_statistic, p_value = ttest_rel(data1, data2, alternative=alternative)\n",
    "        test_name = \"paired t-test\"\n",
    "    else:\n",
    "        # Otherwise, we use the nonparametric Wilcoxon signed-rank test.\n",
    "        test_statistic, p_value = wilcoxon(\n",
    "            data1, data2, alternative=alternative, zero_method=zero_method\n",
    "        )\n",
    "        test_name = \"Wilcoxon signed-rank test\"\n",
    "\n",
    "    return test_name, test_statistic, p_value, p_norm\n",
    "\n",
    "\n",
    "def compute_effect_size(data1, data2, paired=True):\n",
    "    \"\"\"\n",
    "    Compute Cohen's d for paired samples using the pingouin package.\n",
    "\n",
    "    Parameters:\n",
    "        data1, data2 (np.array): Paired data arrays.\n",
    "        paired (bool): Whether the comparison is paired (True by default).\n",
    "\n",
    "    Returns:\n",
    "        cohen_d (float): Computed Cohen's d effect size.\n",
    "    \"\"\"\n",
    "    return compute_effsize(data1, data2, paired=paired, eftype=\"cohen\")\n",
    "\n",
    "\n",
    "def run_all_tests(all_means, top_5_means, high_5_means, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Run all statistical tests between the three groups:\n",
    "    1. High 5% vs. All Means\n",
    "    2. High 5% vs. Top 5% Means\n",
    "    3. Top 5% vs. All Means\n",
    "\n",
    "    Parameters:\n",
    "        all_means, top_5_means, high_5_means (np.array): Arrays of measurements.\n",
    "        alpha (float): Significance level.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): A dictionary containing test names, test statistics,\n",
    "                        p-values, normality p-values, and effect sizes.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Comparison 1: High 5% vs. All Means\n",
    "    test_name1, stat1, p_value1, norm_p1 = choose_and_run_test(\n",
    "        high_5_means, all_means, alternative=\"greater\", alpha=alpha\n",
    "    )\n",
    "    cohen_d1 = compute_effect_size(high_5_means, all_means, paired=True)\n",
    "    results[\"High_vs_All\"] = {\n",
    "        \"Normality_p\": norm_p1,\n",
    "        \"Test\": test_name1,\n",
    "        \"Test_Statistic\": stat1,\n",
    "        \"p_value\": p_value1,\n",
    "        \"Cohen_d\": cohen_d1,\n",
    "    }\n",
    "\n",
    "    # Comparison 2: High 5% vs. Top 5% Means\n",
    "    test_name2, stat2, p_value2, norm_p2 = choose_and_run_test(\n",
    "        high_5_means, top_5_means, alternative=\"greater\", alpha=alpha\n",
    "    )\n",
    "    cohen_d2 = compute_effect_size(high_5_means, top_5_means, paired=True)\n",
    "    results[\"High_vs_Top\"] = {\n",
    "        \"Normality_p\": norm_p2,\n",
    "        \"Test\": test_name2,\n",
    "        \"Test_Statistic\": stat2,\n",
    "        \"p_value\": p_value2,\n",
    "        \"Cohen_d\": cohen_d2,\n",
    "    }\n",
    "\n",
    "    # Comparison 3: Top 5% vs. All Means\n",
    "    test_name3, stat3, p_value3, norm_p3 = choose_and_run_test(\n",
    "        top_5_means, all_means, alternative=\"greater\", alpha=alpha\n",
    "    )\n",
    "    cohen_d3 = compute_effect_size(top_5_means, all_means, paired=True)\n",
    "    results[\"Top_vs_All\"] = {\n",
    "        \"Normality_p\": norm_p3,\n",
    "        \"Test\": test_name3,\n",
    "        \"Test_Statistic\": stat3,\n",
    "        \"p_value\": p_value3,\n",
    "        \"Cohen_d\": cohen_d3,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_results(\n",
    "    all_means, top_5_means, high_5_means, labels, colors, results, scatter=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a box plot with overlaid scatter points for the three groups and\n",
    "    add significance stars based on pairwise comparisons.\n",
    "\n",
    "    Parameters:\n",
    "        all_means, top_5_means, high_5_means (np.array): Data arrays.\n",
    "        labels (list): List of group labels (e.g., ['All', 'Top 5%', 'High 5%']).\n",
    "        colors (list): List of colors for each group.\n",
    "        results (dict): Output from run_all_tests, containing statistical test results.\n",
    "        scatter (bool): To plot or not to plot individual data values.\n",
    "    \"\"\"\n",
    "    data = [all_means, top_5_means, high_5_means]\n",
    "\n",
    "    # Determine significance stars based on p-values from the tests.\n",
    "    significance_top_vs_all = assign_stars(results[\"Top_vs_All\"][\"p_value\"])\n",
    "    significance_high_vs_top = assign_stars(results[\"High_vs_Top\"][\"p_value\"])\n",
    "\n",
    "    plt.figure(figsize=(4, 10))\n",
    "    box = plt.boxplot(data, labels=labels, patch_artist=True, showmeans=True)\n",
    "\n",
    "    # Color the boxes.\n",
    "    for patch, color in zip(box[\"boxes\"], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "\n",
    "    if scatter:\n",
    "        # Overlay scatter points for individual data values.\n",
    "        for i, (dataset, color) in enumerate(zip(data, colors), start=1):\n",
    "            plt.scatter(\n",
    "                [i] * len(dataset), dataset, color=color, alpha=0.7, edgecolor=\"k\"\n",
    "            )\n",
    "\n",
    "    # Calculate y-levels for significance annotations.\n",
    "    y_max_all_top5 = max(np.max(all_means), np.max(top_5_means)) + 0.01\n",
    "    y_max_top5_high5 = max(np.max(top_5_means), np.max(high_5_means))\n",
    "    h = 0.01  # Height offset for significance lines.\n",
    "    star_offset = 0.002\n",
    "\n",
    "    # Add significance line and stars between All and Top 5%.\n",
    "    x1, x2 = 1, 2\n",
    "    plt.plot(\n",
    "        [x1, x1, x2, x2],\n",
    "        [y_max_all_top5, y_max_all_top5 + h, y_max_all_top5 + h, y_max_all_top5],\n",
    "        lw=1.5,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        (x1 + x2) * 0.5,\n",
    "        y_max_all_top5 + h + star_offset,\n",
    "        significance_top_vs_all,\n",
    "        ha=\"center\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    # Add significance line and stars between Top 5% and High 5%.\n",
    "    x1, x2 = 2, 3\n",
    "    plt.plot(\n",
    "        [x1, x1, x2, x2],\n",
    "        [\n",
    "            y_max_top5_high5 + h,\n",
    "            y_max_top5_high5 + 2 * h,\n",
    "            y_max_top5_high5 + 2 * h,\n",
    "            y_max_top5_high5 + h,\n",
    "        ],\n",
    "        lw=1.5,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        (x1 + x2) * 0.5,\n",
    "        y_max_top5_high5 + 2 * h + star_offset,\n",
    "        significance_high_vs_top,\n",
    "        ha=\"center\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    plt.ylabel(\"Tanimoto Similarity\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.ylim(0.03, 0.47)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tanimono(df):\n",
    "    inchi_list = df[\"Metadata_InChI\"].tolist()\n",
    "    tanimoto = []\n",
    "    mols = [Chem.MolFromInchi(inchi) for inchi in inchi_list]\n",
    "    gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "    fps = [gen.GetFingerprint(mol) for mol in mols]\n",
    "    for fp in fps:\n",
    "        sim = DataStructs.TanimotoSimilarity(fps[0], fp)\n",
    "        tanimoto.append(sim)\n",
    "    return tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sims(df):\n",
    "    df_excluded = df.iloc[1:]\n",
    "    n_first_5_percent = int(len(df_excluded) * 0.05) + 1\n",
    "    mean_tanimoto_first_5_percent = df_excluded.nsmallest(\n",
    "        n_first_5_percent, \"Distance\"\n",
    "    )[\"tanimoto_to_target\"].mean()\n",
    "    mean_tanimoto_last_5_percent = df_excluded.nlargest(\n",
    "        n_first_5_percent, \"tanimoto_to_target\"\n",
    "    )[\"tanimoto_to_target\"].mean()\n",
    "    mean_tanimoto_all = df_excluded[\"tanimoto_to_target\"].mean()\n",
    "    return (\n",
    "        mean_tanimoto_first_5_percent,\n",
    "        mean_tanimoto_last_5_percent,\n",
    "        mean_tanimoto_all,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sims(source, screen, eval):\n",
    "    df_inchi = (\n",
    "        eval.screen_embedding_managers[source][screen]\n",
    "        .df[[\"Metadata_JCP2022\", \"Metadata_InChI\"]]\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    best_jcp = (\n",
    "        eval.compute_enrichment_factor_for_screen(\n",
    "            source, screen, \"Embeddings_dinov2\", [5]\n",
    "        )\n",
    "        .sort_values(by=\"EF\", ascending=False)\n",
    "        .iloc[0][\"Metadata_JCP2022\"]\n",
    "    )\n",
    "    res_dic = pd.DataFrame(\n",
    "        eval.compute_ranking(source, screen, \"Embeddings_dinov2\", best_jcp, plot=False)\n",
    "    )\n",
    "    df = res_dic.merge(df_inchi, on=\"Metadata_JCP2022\").drop_duplicates()\n",
    "    df[\"tanimoto_to_target\"] = get_tanimono(df)\n",
    "    return calculate_sims(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_means_ChemBL = []\n",
    "high_5_means_ChemBL = []\n",
    "all_means_ChemBL = []\n",
    "\n",
    "# Assuming `eval` and `get_sims` are predefined\n",
    "for source in [\"ChEMBL\"]:  # Add 'ChemBL' if needed\n",
    "    for screen in tqdm(eval.screen_embedding_managers[source].keys()):\n",
    "        top_5, high_5, all_mean = get_sims(source, screen, eval)\n",
    "        top_5_means_ChemBL.append(top_5)\n",
    "        high_5_means_ChemBL.append(high_5)\n",
    "        all_means_ChemBL.append(all_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_fingerprint(inchi):\n",
    "    try:\n",
    "        gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "        return gen.GetFingerprint(Chem.MolFromInchi(inchi))\n",
    "    except:\n",
    "        print(f\"failed for {inchi}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "df_jump = eval.global_embedding_manager.df\n",
    "\n",
    "df_jump[\"MorganFingerprint\"] = df_jump[\"Metadata_InChI\"].apply(mol_to_fingerprint)\n",
    "df_jump[\"PhenotypicProfile\"] = [\n",
    "    eval.global_embedding_manager.embeddings[\"Embeddings_dinov2\"][i, :]\n",
    "    for i in range(112480)\n",
    "]\n",
    "df_jump = df_jump[~df_jump[\"MorganFingerprint\"].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def compute_similarity(index, phenotypic_profiles, fingerprints, metric=\"cosine\"):\n",
    "    import numpy as np\n",
    "    from scipy.spatial.distance import cdist\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "\n",
    "    n = int(len(phenotypic_profiles) * 0.05)\n",
    "\n",
    "    # Profil phénotypique de la molécule de référence\n",
    "    reference_profile = phenotypic_profiles[index].reshape(1, -1)\n",
    "\n",
    "    # Empreinte Morgan de la molécule de référence\n",
    "    reference_fingerprint = fingerprints[index].reshape(1, -1)\n",
    "\n",
    "    # Similarité Cosinus pour les profils phénotypiques\n",
    "    cosine_similarities = (\n",
    "        1 - cdist(reference_profile, phenotypic_profiles, metric=metric).flatten()\n",
    "    )\n",
    "    top_1000_cosine = np.argpartition(-cosine_similarities, n)[:n]\n",
    "\n",
    "    # Similarité de Tanimoto pour les empreintes Morgan\n",
    "    tanimoto_similarities = (\n",
    "        1\n",
    "        - pairwise_distances(\n",
    "            reference_fingerprint, fingerprints, metric=\"jaccard\"\n",
    "        ).flatten()\n",
    "    )\n",
    "    top_1000_tanimoto = np.argpartition(-tanimoto_similarities, n)[:n]\n",
    "\n",
    "    # Moyenne des similarités pour les top n profils\n",
    "    avg_cosine_tanimoto = tanimoto_similarities[top_1000_cosine].mean()\n",
    "    avg_morgan_tanimoto = tanimoto_similarities[top_1000_tanimoto].mean()\n",
    "\n",
    "    # Moyenne de toutes les similarités Tanimoto\n",
    "    mean_tanimoto_similarity = tanimoto_similarities.mean()\n",
    "\n",
    "    return avg_cosine_tanimoto, avg_morgan_tanimoto, mean_tanimoto_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jump_clean = df_jump.dropna(\n",
    "    subset=[\"PhenotypicProfile\", \"MorganFingerprint\"]\n",
    ").sample(n=10000)\n",
    "\n",
    "phenotypic_profiles = np.stack(df_jump_clean[\"PhenotypicProfile\"].values)\n",
    "fingerprints = np.stack(df_jump_clean[\"MorganFingerprint\"].values)\n",
    "\n",
    "results = Parallel(n_jobs=-1, backend=\"threading\", verbose=10)(\n",
    "    delayed(compute_similarity)(i, phenotypic_profiles, fingerprints)\n",
    "    for i in range(len(df_jump_clean))\n",
    ")\n",
    "\n",
    "df_jump_clean[\"Avg_Cosine_Tanimoto\"] = [r[0] for r in results]\n",
    "df_jump_clean[\"Avg_Morgan_Tanimoto\"] = [r[1] for r in results]\n",
    "df_jump_clean[\"Avg_mean_Tanimoto\"] = [r[2] for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Across all Compounds\",\n",
    "    \"5% Most Similar Phenotypes\",\n",
    "    \"5% Most Similar Structure\",\n",
    "]\n",
    "colors = [\"skyblue\", \"lightgreen\", \"salmon\"]\n",
    "\n",
    "results = run_all_tests(\n",
    "    np.array(all_means_ChemBL),\n",
    "    np.array(top_5_means_ChemBL),\n",
    "    np.array(high_5_means_ChemBL),\n",
    "    alpha=0.05,\n",
    ")\n",
    "\n",
    "print(\"Statistical Test Results:\")\n",
    "for comp, res in results.items():\n",
    "    print(f\"\\nComparison: {comp}\")\n",
    "    print(f\"  Normality p-value: {res['Normality_p']:.10f}\")\n",
    "    print(f\"  Test used: {res['Test']}\")\n",
    "    print(f\"  Test Statistic: {res['Test_Statistic']:.10f}\")\n",
    "    print(f\"  p-value: {res['p_value']:.10f}\")\n",
    "    print(f\"  Cohen's d: {res['Cohen_d']:.4f}\")\n",
    "\n",
    "plot_results(\n",
    "    all_means_ChemBL, top_5_means_ChemBL, high_5_means_ChemBL, labels, colors, results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Across all Compounds\",\n",
    "    \"5% Most Similar Phenotypes\",\n",
    "    \"5% Most Similar Structure\",\n",
    "]\n",
    "colors = [\"skyblue\", \"lightgreen\", \"salmon\"]\n",
    "\n",
    "all_means_Jump = df_jump_clean[\"Avg_mean_Tanimoto\"].to_list()\n",
    "top_5_means_Jump = df_jump_clean[\"Avg_Cosine_Tanimoto\"].to_list()\n",
    "high_5_means_Jump = df_jump_clean[\"Avg_Morgan_Tanimoto\"].to_list()\n",
    "\n",
    "\n",
    "results = run_all_tests(\n",
    "    np.array(all_means_Jump),\n",
    "    np.array(top_5_means_Jump),\n",
    "    np.array(high_5_means_Jump),\n",
    "    alpha=0.05,\n",
    ")\n",
    "\n",
    "print(\"Statistical Test Results:\")\n",
    "for comp, res in results.items():\n",
    "    print(f\"\\nComparison: {comp}\")\n",
    "    print(f\"  Normality p-value: {res['Normality_p']:.10f}\")\n",
    "    print(f\"  Test used: {res['Test']}\")\n",
    "    print(f\"  Test Statistic: {res['Test_Statistic']:.10f}\")\n",
    "    print(f\"  p-value: {res['p_value']:.10f}\")\n",
    "    print(f\"  Cohen's d: {res['Cohen_d']:.4f}\")\n",
    "\n",
    "plot_results(\n",
    "    all_means_Jump, top_5_means_Jump, high_5_means_Jump, labels, colors, results, False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenoseeker-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
